{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calling Oana's methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mutils import bleu_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expl_csv = './../attention/snli_test_expl_csv.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snli_test_no_unk = get_dev_test_original_expl('/data/rosa/data/esnli/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refs:  [['Not', 'all', 'churches', 'have', 'cracks', 'in', 'the', 'ceiling'], ['There', 'is', 'no', 'indication', 'that', 'there', 'are', 'cracks', 'in', 'the', 'ceiling', 'of', 'the', 'church.']]\n",
      "candidates  [['the', 'church', 'can', 'not', 'sing', 'if', 'it', 'is', 'in', 'the', '.'], ['the', 'church', 'is', 'not', 'necessarily', 'filled', 'with', '.'], ['a', 'choir', 'is', 'not', 'singing', 'at', 'a', 'baseball', '.'], ['not', 'all', 'women', 'are', '.']]\n",
      "references  [[['Not', 'all', 'churches', 'have', 'cracks', 'in', 'the', 'ceiling'], ['There', 'is', 'no', 'indication', 'that', 'there', 'are', 'cracks', 'in', 'the', 'ceiling', 'of', 'the', 'church.']], [['\"Filled', 'with', 'song\"', 'is', 'a', 'rephrasing', 'of', 'the', '\"choir', 'sings', 'to', 'the', 'masses.\"'], ['hearing', 'song', 'brings', 'joyous', 'in', 'the', 'church.']], [['A', 'choir', 'sing', 'some', 'other', 'songs', 'other', 'than', 'book', 'at', 'church', 'during', 'the', 'base', 'play.', 'they', 'cannot', 'see', 'book', 'and', 'play', 'base', 'ball', 'same', 'time.'], ['The', 'choir', 'is', 'at', 'a', 'chruch', 'not', 'a', 'baseball', 'game.']], [['the', 'woman', \"could've\", 'been', 'old', 'rather', 'than', 'young'], ['There', 'is', 'no', 'indication', 'that', 'the', 'woman', 'is', 'young.']]] \n",
      "\n",
      "\n",
      "\n",
      "refs:  [['The', 'people', 'can', 'examine', 'standing', 'instead', 'of', 'sitting', 'and', 'they', 'can', 'be', 'next', 'to', 'a', 'river,', 'ocean,', 'not', 'necessarily', 'the', 'beach.'], ['We', 'have', 'no', 'idea', 'if', 'they', 'are', 'on', 'a', 'beach', 'to', 'tan,', 'they', 'could', 'be', 'there', 'for', 'a', 'number', 'of', 'reasosn.']]\n",
      "bleu:  0.157313656853\n"
     ]
    }
   ],
   "source": [
    "bleu_score = bleu_prediction(expl_csv, snli_test_no_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mutils import bleu_inter_annotations_expl3_wrt_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu:  60.1917151437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_inter_annotations_expl3_wrt_12(snli_test_no_unk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my method of computing bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum([1,2]))/len([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/rosa2.7/lib/python2.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "bleu:  0.0709956921137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07099569211372728"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bleu each time and take avg at the end\n",
    "def my_bleu_prediction(pred_file, data):\n",
    "    candidates = []\n",
    "    references = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    f = open(pred_file)\n",
    "    pred_reader = csv.DictReader(f)\n",
    "    k = -1\n",
    "    for row in pred_reader:\n",
    "        k += 1\n",
    "        if k % 5000 == 0:\n",
    "            print k\n",
    "        if k < len(data['expl_1']):\n",
    "            prediction = row['pred_expl'].strip().split()\n",
    "            candidates.append(prediction)\n",
    "            current_refs = []\n",
    "            for j in range(1, 3):\n",
    "                current_refs.append(data['expl_' + str(j)][k].strip().split())\n",
    "            \n",
    "            #print 'refs: ', current_refs\n",
    "            references.append(current_refs)\n",
    "            #print \"candidates \", candidates\n",
    "            #print \"references \", references, '\\n\\n\\n'\n",
    "            bleu_scores.append(corpus_bleu([current_refs], [prediction]))\n",
    "    \n",
    "    #bleu_score = corpus_bleu(references, candidates)\n",
    "    bleu_score = float(sum(bleu_scores))/len(bleu_scores)\n",
    "    print 'bleu: ', bleu_score\n",
    "    f.close()\n",
    "    return bleu_score\n",
    "\n",
    "my_bleu_prediction(expl_csv, snli_test_no_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu:  16.7942828288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.79"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bleu all together at the end (same as Oana)\n",
    "# but!!! pass in tokenized sentences instead of complete sentences\n",
    "def my_bleu_inter_annotations_expl3_wrt_12(data):\n",
    "    candidates = []\n",
    "    references = []\n",
    "\n",
    "    for k in range(len(data['expl_1'])):\n",
    "        #if k > 2:\n",
    "            #break\n",
    "        candidates.append(data['expl_3'][k].strip().split())\n",
    "        current_refs = []\n",
    "        for j in range(1, 3):\n",
    "            current_refs.append(data['expl_' + str(j)][k].strip().split())\n",
    "        references.append(current_refs)\n",
    "        #print \"candidates \", candidates\n",
    "        #print \"references \", references, '\\n\\n\\n'\n",
    "    \n",
    "    bleu_score = 100 * corpus_bleu(references, candidates)\n",
    "    print 'bleu: ', bleu_score\n",
    "    return round(bleu_score, 2)\n",
    "\n",
    "my_bleu_inter_annotations_expl3_wrt_12(snli_test_no_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates  [['Not', 'all', 'churches', 'have', 'cracks', 'in', 'the', 'ceiling.'], ['If', 'the', 'church', 'choir', 'sings', 'then', 'the', 'church', 'is', 'filled', 'with', 'song.'], ['A', 'baseball', 'game', 'isn\\xe2\\x80\\x99t', 'played', 'at', 'a', 'church.'], ['Not', 'all', 'women', 'are', 'young.'], ['One', 'must', 'be', 'happy', 'in', 'order', 'to', 'have', 'a', 'big', 'grin.']]\n",
      "references  [[['Not', 'all', 'churches', 'have', 'cracks', 'in', 'the', 'ceiling'], ['There', 'is', 'no', 'indication', 'that', 'there', 'are', 'cracks', 'in', 'the', 'ceiling', 'of', 'the', 'church.']], [['\"Filled', 'with', 'song\"', 'is', 'a', 'rephrasing', 'of', 'the', '\"choir', 'sings', 'to', 'the', 'masses.\"'], ['hearing', 'song', 'brings', 'joyous', 'in', 'the', 'church.']], [['A', 'choir', 'sing', 'some', 'other', 'songs', 'other', 'than', 'book', 'at', 'church', 'during', 'the', 'base', 'play.', 'they', 'cannot', 'see', 'book', 'and', 'play', 'base', 'ball', 'same', 'time.'], ['The', 'choir', 'is', 'at', 'a', 'chruch', 'not', 'a', 'baseball', 'game.']], [['the', 'woman', \"could've\", 'been', 'old', 'rather', 'than', 'young'], ['There', 'is', 'no', 'indication', 'that', 'the', 'woman', 'is', 'young.']], [['a', 'grin', 'suggests', 'hapiness.'], ['A', 'WOMAN', 'WITH', 'BIG', 'GRIN', 'IS', 'HAPPY']]] \n",
      "\n",
      "bleu:  0.0925415731903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bleu each time and take avg at the end\n",
    "def my_bleu_inter_annotations_expl3_wrt_12(data):\n",
    "    candidates = []\n",
    "    references = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    for k in range(len(data['expl_1'])):\n",
    "        if k == 5:\n",
    "            print \"candidates \", candidates\n",
    "            print \"references \", references, '\\n'\n",
    "        candidates.append(data['expl_3'][k].strip().split())\n",
    "        current_refs = []\n",
    "        for j in range(1, 3):\n",
    "            current_refs.append(data['expl_' + str(j)][k].strip().split())\n",
    "        references.append(current_refs)\n",
    "        #print \"candidates \", candidates\n",
    "        #print \"references \", references, '\\n\\n\\n'\n",
    "        bleu_scores.append(corpus_bleu([current_refs],[data['expl_3'][k].strip().split()]))\n",
    "    \n",
    "    #bleu_score = 100 * corpus_bleu(references, candidates)\n",
    "    bleu_score = float(sum(bleu_scores))/len(bleu_scores)\n",
    "    print 'bleu: ', bleu_score\n",
    "    return round(bleu_score, 2)\n",
    "\n",
    "my_bleu_inter_annotations_expl3_wrt_12(snli_test_no_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rosa2.7",
   "language": "python",
   "name": "rosa2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
